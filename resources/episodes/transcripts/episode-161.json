{
  "episode_number": "161",
  "episode_title": "How Lindy Simplifies AI-Powered Business Automation with Elizabeth Knopf",
  "guest_name": "Elizabeth Knopf",
  "business_name": "",
  "transcript": "ï»¿Nikolas Hulewsky (00:00.947)\r\nAll right, Liz, we've got another jam packed week. I'm freaking excited. A couple of things I want to talk about first, obviously go over some of the new releases that happened. Open AI with 01 and 03 mini, I think are the new reasoning models that they have out. And then Google's Flash 2.5. So we'll talk about those and just have a brief explanation for like, okay, what does this mean? What progress have we made? And then on the backend, you're going to show us a Lindy tutorial. At least one. Okay. All right.\r\n\r\n\r\nLiz (00:26.016)\r\nAwesome. Looking forward to it. At least one.\r\n\r\n\r\nNikolas Hulewsky (00:30.419)\r\nSo I want to ask a question about this because it took me a while to really understand this. There are kind of two types of models. There are probably actually more types of models, but from my perspective, there are two types of models. There's the traditional LLMs and then there are these what they call reasoning models. And OpenAI has the 01, 03, 01 minis, whatever, all of those reasoning models. Google has what now Flash 2.5.\r\n\r\n\r\nI think anthropics reasoning model, is there a name for it? Okay. don't remember. Or is it just deep thinking or something like that?\r\n\r\n\r\nLiz (01:05.678)\r\nYeah, I think, I don't know if they've, I mean, it's in 3.7 Sonnet. So I don't know if they've, they've sort of like made it just from a UI perspective, but I don't actually know if it's doing something differently. Yeah.\r\n\r\n\r\nNikolas Hulewsky (01:19.153)\r\nOkay. But can you briefly talk about, or I can set the context. Like what, what's the difference between a reasoning model and these traditional LLMs? Yes. Okay. Okay. So from, from what I understand is traditional AI models that have been trained is they've taken a ton of data, right? And they've been trained on the data. And essentially what they're doing is using statistics to predict the next word. That's a very, very dumbed down way to say it, but that's essentially what I understand is they're just predicting.\r\n\r\n\r\nLiz (01:28.45)\r\nHow about you set the context and then I can.\r\n\r\n\r\nNikolas Hulewsky (01:49.309)\r\nwhat the answer is going to be based on all of the past information that it's gotten. So it's a predictive model based on the past. These reasoning models work off of like chain of thought. They're solving a puzzle kind of like we do where they actually work through, I'm trying to find the population of Bhutan. Where would I go to find the population of Bhutan? All right, the last census statistics were in 2020. What was their average growth rate? Okay, let me go to this.\r\n\r\n\r\nLiz (01:53.07)\r\nMm-hmm.\r\n\r\n\r\nNikolas Hulewsky (02:15.325)\r\ndata source. So it's like, it's actually going thinking through how it might solve a problem. So there, there are two different approaches. Whereas one is not novel. One is like looking at the past, giving you an output based on what it's seen. The other, reasoning models, the hope is that they will actually produce novel work, new work. how was that synopsis?\r\n\r\n\r\nLiz (02:19.502)\r\nMm-hmm.\r\n\r\n\r\nLiz (02:39.074)\r\nYeah, no, I think that's good. Yeah, I mean, I think that's probably the simplest way to describe it. Again, it's just basically taking like you as a human, if you're interacting with that LLM and asking a question and then say, no, if you can now reference this. So this also this term of chain of thought is basically just taking through like structuring, how would you approach, you would create basically like first your outline, like if you're writing a book or something.\r\n\r\n\r\nYou would start with writing an outline and then from that outline, you would then, you know, take parts, but each part. And so I would say it's sort of similar in that of like, you're taking how you would approach a problem, structuring it, and then going through iteratively. and so like I've, you know, I think a lot of people started off with engaging with LLMs sort of doing this when you're engaging in like some of the, the trick tips and tricks that I've used is like, find an expert. What is their framework?\r\n\r\n\r\nand then that sort of a chain of thought, then you use that framework to then solve something. And so they're just doing it now on their own. Some people are also sort of referring to this a little bit of like agentic behavior because they're able to go and do things on their own and sort of self refine. like, as like we, I know you do this as well as like, you'll try to figure out a meta prompt. So you'll go and sort of say, okay, I want to sort of achieve this, but like, I don't know what the full good prompt is. so then you'll have.\r\n\r\n\r\nthe LLM go and figure that out. Now it can basically do that on its own of saying like, here's sort of like the goal. Now let me think through what is the structure and problem solving approach to getting to that answer. So I think I just basically in more words.\r\n\r\n\r\nNikolas Hulewsky (04:19.089)\r\nYeah. No. the hope is, whereas right now with these models, these LLMs like GPT-4.0, it does a really good job of taking a lot of disparate information and then synthesizing it and then telling you, hey, this is what I got out of it. So can take really broad data sets and refine them into something understandable. The hope is with these reasoning models is that they'll be able to not just synthesize, but actually take things from disparate places and say,\r\n\r\n\r\nLiz (04:32.056)\r\nMm-hmm.\r\n\r\n\r\nNikolas Hulewsky (04:48.179)\r\nYou know what, there's this principle in engineering and we took this thing from chemistry. and we also took this heuristic and you know, the, we know from anthropology and now we can create something novel. and so the applications for medicine, the applications for science, the applications for space technology, the hope is that this will actually help us create new things as opposed to just synthesizing large data sets that we've already had.\r\n\r\n\r\nLiz (05:12.974)\r\nAnd we were actually already seeing that start to happen. Like I believe I saw in some of the news that there was some cancer breakthroughs. So I think maybe the first one is being able to detect things that humans can't detect. So that's sort of on the visual side of things where I know that like X-rays and other things were identifying cancer cells sooner or anomalies. That's one example and that's sort of simplified, but now it's sort of, as you're saying, cross-disciplinary.\r\n\r\n\r\nI agree and I think that it will play out. I don't see from why that wouldn't happen. The thing I don't see happening is it necessarily coming up completely with new ideas. Because again, you have to have the knowledge from somewhere. But then you can also argue that with humans. I don't know. I mean, I could be totally wrong and it's gonna end up creating its own novel.\r\n\r\n\r\nNikolas Hulewsky (06:06.011)\r\nWhy? I don't think these models necessarily are going to be the ones that cure cancer, but it's the hope is like, okay, if we're creating chain of thought and it's thinking through how to solve the problem as opposed to just mimic what it's already read and then synthesize and give it to us. The, you know, the hope is that that gets us down a path where we can solve these problems. But from what I've seen, I want to get your opinion on it. my experience is if I want to write something, if I want to think through a logical arc, not even think through a logical argument.\r\n\r\n\r\nLiz (06:09.537)\r\nNo, no, no.\r\n\r\n\r\nNikolas Hulewsky (06:35.729)\r\nIf I want to think through how I'm phrasing something, if I want to just get a quick answer from the web, I'll still go to the traditional LLM models because those are quick answers and the speed is very fast. But I want to think through a complex problem like, hey, I'm negotiating with this person. Here are the deal terms. Here's what's important to them. Here's what's important to me. What am I seeing? What am I not seeing? I've actually started going to the reasoning models with\r\n\r\n\r\nwith some success. For me, that's been really helpful. I don't know what your opinion is.\r\n\r\n\r\nLiz (07:05.934)\r\nThat a thousand percent, a thousand percent. Like it's able now to go deep, both from like taking more sources than we would probably, either of us ever have time to research, like, you know, 30, 40, you know, I've even seen, think, like a hundred sources that it'll pull. And then it'll pull frameworks, it'll pull, so absolutely, like these are going deep. are, like I've gotten some pretty long structured outputs from...\r\n\r\n\r\nGrok, from Gemini, from ChatGPT, from Claude, like all of them now, they're all sort of racing in similar directions. all sort of like, one of them has like the breakthrough and then the next one, it's like next week, it's on par. But absolutely, like those problems are definitely solvable. Again, if it's for negotiation for business, like they're there. Like these problems that you have, like I can't imagine going to\r\n\r\n\r\nan expert who has been public now because you can access it through your LLF. Like you don't need consultants. You don't need to have like an advisor. I mean, I shouldn't say that because like for legal and health and all that you probably do.\r\n\r\n\r\nNikolas Hulewsky (08:15.155)\r\nYou should. No, you should. You should definitely still have an advisor. like what I'm noticing is it's cutting you down on like 80 % of the time that you need to get in order to get up to speed. It's like, cool. It's got, it's gotten you 80 % of the way there. And then you can go and get a specialist or an advisor who can get you the last 20%. Whereas in the past, you're spending a lot more time with that advisor kind of to get up to speed. The other interesting thing that I found with these models is if anyone's used them, they, at least on open AI, they were super slow.\r\n\r\n\r\nLiz (08:43.502)\r\nMm-hmm.\r\n\r\n\r\nNikolas Hulewsky (08:44.401)\r\nAnd so it would take time to like, Hey, here's my problem set. What do you think? And it would be like deep research where it just takes five minutes to get a response back to you. From what I understand these updates like flash 2.5 in particular is they're fast. They're like, they're actually responsive, not responsive, but they're quick now with their responses. Is that right?\r\n\r\n\r\nLiz (08:58.06)\r\nYes.\r\n\r\n\r\nAbsolutely. it's very noticeable. like that never really bothered me as a user, but now it's like, it's pretty impressive, to think how fast it is. Like it's again, gathering all this data and processing and synthesizing it. It's just, I mean, it is pretty incredible. And I think like we get jaded since we're in the space constantly. but I mean, to have that speed of analysis, like some of the things I was working on, I'm like, wow, this literally would have taken.\r\n\r\n\r\nlike an analyst, a full week of work. And I'm like, I'm now doing things like with, well, maybe I can even demo this with one of the tools. I had like it's structured out a contract and some output data that like literally you'd have to read, you know, 20 pages, then you'd have to get another contract, read another 20 pages, obviously consuming that information and then structuring the output. that, you know, it's like in a minute now. So, and literally I remember had like full teams doing\r\n\r\n\r\nNikolas Hulewsky (09:57.373)\r\nCrazy.\r\n\r\n\r\nLiz (10:01.096)\r\nvarious permutations of that. And again, it's just like you save so much money and time and capacity that now people can like take action and do so much more with these tools.\r\n\r\n\r\nNikolas Hulewsky (10:12.241)\r\nYeah. I mean, I kind of think of it as, okay, 4.0, let's say open AI, know, Chad GPT 4.0. It's kind of just like an entry level analyst. Cool. They have some experience, but I just need you to run this report that I've told you to run a million times. Or I need you to do this analysis on a known problem set. Whereas the reasoning models are like, I don't know, a manager, executive level, MBA level thought partner. Where it's like, Hey, this is a new problem set that we've never encountered before.\r\n\r\n\r\nLiz (10:41.496)\r\nYep. Yep.\r\n\r\n\r\nNikolas Hulewsky (10:41.607)\r\nI need your help thinking through it. That's not necessarily the best for this entry level analyst, although they can offer some insights, but I need somebody who can be a thought partner with me. It's like actually think through how to solve this problem. So anyways, that's how I think about reasoning versus traditional LLMs.\r\n\r\n\r\nLiz (10:55.5)\r\nYeah, no. it's interesting because it's like, these are also now becoming agentic. So where it's like just synthesizing the information, they're also being able to now take action and leverage tools, which is like, by the end of the year, I don't think we're going to even recognize where things are. mean, and I think that's something interesting too, is just the acceleration in the last like five months has been\r\n\r\n\r\nextraordinary. People, you you're in it, you don't see it, but yeah. Okay. So first with agentic. So agentic basically means that, okay, you're getting information and now you actually want to take action. So agentic really means that it's doing a thing. So even when it's doing this research, you could hypothetically consider that agentic because it's going out and searching the web, gathering sources, and that is sort of an agentic behavior. is doing something. It's not just synthesizing.\r\n\r\n\r\nNikolas Hulewsky (11:26.215)\r\nWill you talk about that a little bit more? What does agentic mean?\r\n\r\n\r\nLiz (11:53.966)\r\nor analyzing. And so now there's.\r\n\r\n\r\nNikolas Hulewsky (11:57.349)\r\nIt's not passive. It's not, hey, here's the data. I'm giving it to you. Give me an output. It's now go find the data, synthesize it and give me an output.\r\n\r\n\r\nLiz (12:02.606)\r\nRight, exactly. So in some ways there's like a gray area and I'm sure the hardcore people will be mad at me about this, but there is some overlap between the chain of thought because technically you could say that's agentic because it is again chaining together different prompts. But again, now this is actually going outside of its little bubble of its training data and going\r\n\r\n\r\nNikolas Hulewsky (12:14.867)\r\nYou\r\n\r\n\r\nLiz (12:31.991)\r\nto pull other resources and doing a thing. And so this is really where it's impactful for SMBs and for businesses in general, because now it's not just saying like, here, write something for me. It's actually saying like, gather the information, gather the competitive intelligence, put it together, structure it, an analysis, and then create a visualization of my market map and a card for my sales team so that they know how to do objection.\r\n\r\n\r\nyou can actually now do tasks that you would literally have a person, a marketing analyst do and take over that role. And we're just going to continue to see that. And again, the acceleration of this and the ease of this and accessibility of this is just at a level that no one has seen in history. again, like I was just thinking about where we were a year ago, where if you wanted to do anything that was agentic, that would go outside of the chat window.\r\n\r\n\r\nNikolas Hulewsky (13:05.811)\r\nMm-hmm.\r\n\r\n\r\nLiz (13:30.062)\r\nYou would have to know code and use this thing called lane chain and use like Some frameworks and it was a little bit complicated now It's just like think like it is going off and doing a thing from literally your chat window now with MCPs and we won't go into that today But it's just becoming accessible where you can use existing tools to achieve tasks\r\n\r\n\r\nNikolas Hulewsky (13:53.971)\r\nYeah, I mean agents agents are coming if people have been talking about agents for a while We'll see how well they get dialed in but it's really like Liz was saying it's going from here I'm gonna give I'm gonna give you all the information to Go source the information Make a decision execute the task knowing the end state result that I want out of it. So I'm excited for that\r\n\r\n\r\nLiz (14:15.694)\r\nThere were other things that people haven't harped on enough, but I actually think it's pretty interesting. So one was a chat GBT enabled memory, which means it can remember all of your conversations and why I think this is super impactful and important.\r\n\r\n\r\nNikolas Hulewsky (14:29.491)\r\nOkay.\r\n\r\n\r\nLiz (14:34.658)\r\nis before you would have to basically recreate the context, whether it was in a project or a new chat. And at some point, know, chats get too long. So you have to restart it and it gets frustrating because you've just had this conversation and restart it. So now it can actually access all of your chats, which, you know, on the one hand, people are concerned with privacy. again, like guardrails at the end of the day, we're all, anyone who's on the internet, like privacy is sort of a thing of the past at this point.\r\n\r\n\r\nBut then again, like you can now like see your timeline access like your evolution of thinking. You can access things that like, a year ago, I remember talking or thinking about this one thing, but I don't remember this or that. And now you have access to that in such an accessible way. Yeah.\r\n\r\n\r\nNikolas Hulewsky (15:17.779)\r\nwas going to ask you, how does it work? Because I'm just thinking from the perspective, in order for me to get the model to act the way that I want it to act or to have enough background on me, I've got to give it context. And in order to give it context, I've got to enter into the context window. And in order to get the context window, it's got to be under 100,000, 120, whatever, tokens. So what has OpenAI done that has given it memory? Is it training it on our data set?\r\n\r\n\r\nLiz (15:37.902)\r\nMm-hmm.\r\n\r\n\r\nLiz (15:44.658)\r\nso, so, okay. So there's the con. So this is the other piece actually is the context window. This has been the limiting factor for use cases and for this aspect of memory. so I don't know from a technical standpoint, so I won't be able to speak technically to what innovations they're doing to enable how they're doing that. but I know that the context windows, they're able to expand and\r\n\r\n\r\nThey thought it's interesting because they thought at one point there was like a hard ceiling and that obviously has been crushed. And, actually Google was the first one with Gemini to break that context window. think it has like a million and, and chat GBT though is pretty phenomenal. Like I was trying last night to see if I could do a comparison and I just kept loading up documents and documents and documents and chat GBT was handling it. So they technically supposedly have less, but.\r\n\r\n\r\nNikolas Hulewsky (16:27.123)\r\nIt's a million year.\r\n\r\n\r\nLiz (16:42.464)\r\nlike you really need to have a ton of stuff to shove in there to see that difference. So I'll get back to you on some of these technical terms, but basically they are innovating here and a lot of the things we had preconceived notions about even a couple months ago seem to be, you know, they're breaking through from a technical standpoint. Yeah.\r\n\r\n\r\nNikolas Hulewsky (16:50.707)\r\nYeah, that's cool.\r\n\r\n\r\nNikolas Hulewsky (17:04.945)\r\nYeah, the memory thing is cool. What was the other thing you mentioned? the context windows.\r\n\r\n\r\nLiz (17:07.32)\r\nSo the context windows, those were really, and the context window is sort of enabling that. And I'm wondering too, I don't know if the way that they're doing it with the personalization and memory, it's similar to like how you, I don't want to put out too many technical terms, but like have like a vector database. So I don't know if they're using that methodology to approach your own cat history is basically, it's like this large database. Cause I mean, again, like the models are trained on a massive amount of data. So yeah.\r\n\r\n\r\nNikolas Hulewsky (17:36.221)\r\nWell, and for business owners, what I found most interesting about the update to the context window is that if you go into chat, GPT, anybody who's listening, you go right now and you enter a question to chat, GPT, it's still the same. There's still like the whatever 120,000 token context window, but business owners and just anybody in tech, they've been able to use open AI's LLM through API keys. So they'll, they'll use an automation like\r\n\r\n\r\nAutomation software like Zapier and then they'll connect Google Sheets with a software with open AI. So there's a link to a survey and then the data is given and then the data goes to open AI for it to synthesize it and, and essentially to create a summary, let's say, and then it spits out to a Google Sheet. That was a very like archaic way to explain it, but like for simplicity sake, that's what it is. Well, now with the APIs, because you've built them,\r\n\r\n\r\nyou can they've expanded the context window of the APIs so you can give it much more information to make your analysis or your whatever it's doing for you much better and much more refined whereas in the past you only had 120 000 tokens what's the new context window now with open ai do you remember\r\n\r\n\r\nLiz (18:51.95)\r\nOpen AI when I looked, I had actually, hold on, I did have like a grid I found that compared them. Let me see where I had it pulled up. If you give me one second.\r\n\r\n\r\nNikolas Hulewsky (19:06.643)\r\nLet's see.\r\n\r\n\r\nLiz (19:08.106)\r\nI did have this one sec.\r\n\r\n\r\nLiz (19:14.332)\r\nI want to say it was 250,000, but I did have it. I think Gemini pulled up a grid for me.\r\n\r\n\r\nNikolas Hulewsky (19:33.171)\r\nOne million. One million. Open AI. Yeah, yeah, I'm reading it right here.\r\n\r\n\r\nLiz (19:34.19)\r\n1 million. Yeah, that's for a gem. Wait, open AI has a million now? Okay, that's why. Yep. Because Google\r\n\r\n\r\nNikolas Hulewsky (19:41.531)\r\nIntroducing GPT 4.1 in the API, larger context window supporting up to 1 million tokens of context. Holy balls. That is so much freaking context.\r\n\r\n\r\nLiz (19:51.95)\r\nThat's, that's huge, huge, huge, huge. So I'll just, so one example, okay. So I'll give you sort of a concrete example, how this can be impactful at like a S a business. so I had a project where we had, I don't know if I mentioned this on a previous podcast or not, but, we had a project where it was going to cost us about $10 million to review our\r\n\r\n\r\nNikolas Hulewsky (19:55.579)\r\nmy gosh.\r\n\r\n\r\nLiz (20:21.294)\r\ncustom contracts that were, these were like anywhere from 30 to a hundred page contracts. Like it was very large company enterprise deals. And we had a bunch of accounts receivables. We knew we're stuck in those contracts and we had a bunch of issues with our accounting team and we had a bunch of issues with forecasting because we did not know everything with our contracts because we were constantly amending them, rewriting them midway through. So.\r\n\r\n\r\nWe would have analysts that were spending a ton of time going through the contracts just so that the sales person could have a productive conversation with the prospect. We were going to do a project that we estimated would cost us about $10 million just to clean up the data and be able to structure the information from those contracts and put that into our database. Just. Yeah.\r\n\r\n\r\nNikolas Hulewsky (21:07.955)\r\nWhoa, whoa, whoa, whoa, whoa, whoa, whoa,\r\n\r\n\r\nLiz (21:14.69)\r\nYep, because you would have to have people reading through all the contracts. These were long contracts. Then you'd have to have them put it in spreadsheet. Then you need someone to QA it. Then you need to figure out all the expenses associated with an employee. And so again, like we had, it was a large company and so, know, 10 million, it was a lot, but you know, relative to the size, was other question. But we ended up not going ahead with this project and just saying like, maybe we have some AR missing and like, well. And then we had to like,\r\n\r\n\r\nNikolas Hulewsky (21:20.839)\r\nYeah.\r\n\r\n\r\nLiz (21:43.916)\r\nyou re-figure out the go-forward process. But anyways, but now that kind of process, like again, depending upon how you structure it, like a couple thousand dollars to run that through if you're using the APIs. And if you're not, then it's just like, you know, how much can you feed it at what time period? So like the impact to businesses, if you're not taking advantage of all this is just, it's incredible. And like a couple of the companies I'm now...\r\n\r\n\r\nNikolas Hulewsky (21:58.227)\r\nWow.\r\n\r\n\r\nNikolas Hulewsky (22:11.667)\r\nWell, because there, well, there's the primary impact, which was, should we spend $10 million or not spend $10 million to get the data cleaned up enough for us to have a better idea of what our AR is? That was like the, that was the primary impact. But the secondary impact was they probably didn't collect as much as they should have, right? Like if they had gotten the data correct, then they could have gone and actually followed up on that outstanding accounts receivable. So.\r\n\r\n\r\nLiz (22:22.51)\r\nMm-hmm.\r\n\r\n\r\nNikolas Hulewsky (22:38.995)\r\nAnd there's probably tertiary effects that I'm not even thinking of, but those are two massive impacts with this technology. Now they could have done it for, even if it was $100,000, but then they have a clean data set and they can go and fix their AR problem. That's insane. $10 million. How much data did they have?\r\n\r\n\r\nLiz (22:56.174)\r\nI mean, there was a lot. There were a thousand contracts and there were long contracts and five contracts minimum per customer. So again, large company, these are...\r\n\r\n\r\nNikolas Hulewsky (22:58.578)\r\nYeah.\r\n\r\n\r\nNikolas Hulewsky (23:03.644)\r\nYeah, yeah, yeah.\r\n\r\n\r\nNikolas Hulewsky (23:07.269)\r\nOkay, here's a question I have and then we'll get to a presentation, not presentation, but like walking through the software. I've had OpenAI, any of these LLMs look at data for me and then provide me summary of the data. And I still get hallucinations. So for example, I did a lot of these AI conversations. I had like 30 of them. I put them all.\r\n\r\n\r\nI got them cleaned and I put them all into a data file and I said, hey, what are the most used LLMs? Or like, what are the primary LLMs? That's what it was. What are each person's primary LLM? And there was one person who said Gemini and I remembered it because they were like the only person who said Gemini. And so when I looked at the output, that person, their primary LLM was not Gemini, it was something else. And I was like, hey, this isn't right. It's missing David's Gemini.\r\n\r\n\r\nand it's missing three other people. Abby's not on here and John and whatever else. And it was like, yeah, you're right. My bad. And then it went back and fixed it. So that wasn't even a math problem. It wasn't even like, Hey, take this data. Tell me if it's correlated or not. And then, you know, tell me what the R squared is so that I can see whether or not it's a good fit. This was just what it's supposed to be good at synthesizing data. And it still didn't do it right for me. How do you make sure that that doesn't happen? Cause when you're a small business owner and you're synthesizing this data and you're trying to make decisions off of it, you can't.\r\n\r\n\r\nbe making decisions off of bad data, but how do I even know how to QA it?\r\n\r\n\r\nLiz (24:38.36)\r\nYep. So, okay. So I wouldn't say I have a hundred percent fixed this or anything, but there are some tactics and approaches you can do that. So you're going to have to use the APIs. And the reason being is if you, you know, we were talking chain of thought, well, it's sort of like chaining together different LLMs and have them check their work. And then basically what you would do is have like, you can even have, so we showed make.com and make.com you could have two chat GPT modules or chat GPT plus Anthropic plus\r\n\r\n\r\nand have them all do a QA on the outputs. So that's one piece of it.\r\n\r\n\r\nNikolas Hulewsky (25:14.109)\r\nTell me what that, like what does that mean? They're doing a QA, like what do you do?\r\n\r\n\r\nLiz (25:16.686)\r\nSo you would prompt it and basically say like check the work of the previous LLM. Is this accurate? Can you find this? Where can you find this? Can you provide the source and specific like timestamp or reference in the document so that you are you can get closer? If you chain them together, you can help at least mitigate that. I can't say it's like a hundred percent, but that's what happens.\r\n\r\n\r\nNikolas Hulewsky (25:29.587)\r\nHmm.\r\n\r\n\r\nNikolas Hulewsky (25:39.239)\r\nWell, it's like any human, right? Like you're going to, you'll still have mistakes with humans as well. So I could, I could just go to one of these models and say like, Hey, I want to develop a QA system, help me create it, which is good. So let's say that you have that make automation set up and the first set of analysis is open AI, and then you've got Claude and you've got Gemini doing the QA. Are they doing, are they running the same exact prompt and then comparing notes or are they just taking like a sample size?\r\n\r\n\r\nLiz (25:48.91)\r\nYes.\r\n\r\n\r\nLiz (25:56.91)\r\nYep.\r\n\r\n\r\nNikolas Hulewsky (26:09.637)\r\nand comparing the sample size.\r\n\r\n\r\nLiz (26:11.118)\r\nSo I've I have done it and again I can maybe run a test and we can do a test off I don't know some kind of test to see I don't know See which one which method is is best. But what I have found is You can you can do sort of two things like one you have them all with the same prompt see if they have different outputs and they all will have slightly different outputs, but like if there is sort of\r\n\r\n\r\nNikolas Hulewsky (26:20.755)\r\nthat stuff.\r\n\r\n\r\nLiz (26:39.874)\r\nsomething you understand to be like a binary or like yes or no, this is correct. Then you have all three basically analyzed. And again, you can do this where you have the same prompt and then have them analyze each other. like you would have, first run through each of those independently. Then you would have like Claude check Gemini's work and check someone else's work or GPT's work.\r\n\r\n\r\nNikolas Hulewsky (26:57.576)\r\nHmm.\r\n\r\n\r\nLiz (27:09.422)\r\nAnd then do the same and sort of create that. So again, it just depends on how level the level of complexity and Concern you have and I haven't done enough like iterations of this to see what approach is best But now I'm gonna put that on my to-do list so that we can actually get to an answer and see which methodology will actually give us Clear output. Well, yeah, I think that would be a fun little exercise to see Which one works the best?\r\n\r\n\r\nNikolas Hulewsky (27:37.629)\r\nSo what's just really quickly what's interesting is like there's always going to be an error rate. The error rate's not going to be zero, at least as far as we know. the comparison I would draw is Tesla full self-driving versus human driving. So I don't remember what the error, what it is. I think it's like, I don't know, five fatalities per billion miles driven or something like that. Regular cars, but with full self-driving it's like.\r\n\r\n\r\n0.1 fatalities per billion miles driven. So it's like, still gonna be accidents. There's still gonna be problems. There's gonna be things that are an error, but the error rate, you wanna get it down, obviously, less than a human. Otherwise, you're just trading one problem set for another. So, all right, thanks for the QA thing. That was really interesting. It's something that I've been thinking a lot about and I think I can work on.\r\n\r\n\r\nLiz (28:24.76)\r\nAnd I do believe there are people who have actually built out some tools, some QA tools, at least for coding for more. Like again, I wouldn't put my data and analytics yet into a fully like, you know, trust everything that it says, I would definitely verify. But I have actually been experimenting with Manus, which is a Chinese company, but they're having a lot of companies come out and compute them. But, and maybe I can even show you some of the stuff they've,\r\n\r\n\r\nNikolas Hulewsky (28:48.295)\r\nHuh?\r\n\r\n\r\nLiz (28:53.442)\r\nbeen accurate on a lot of the data analytics that I have thrown its way, which I found interesting. And so I think we're close. I think we're close. Okay. So let me pull up some. All right. Okay. So I'm, I'm been, okay. So the things I've been playing around with, so MCPs we won't get into today, but that I'm really pumped on. And I think that's actually going to be more impactful than people are giving cred to. Two.\r\n\r\n\r\nNikolas Hulewsky (29:00.027)\r\nYeah, me what you're excited about this week. I want to know.\r\n\r\n\r\nAnything. I don't care.\r\n\r\n\r\nLiz (29:23.362)\r\nI think the most impactful for the SMB audience is gonna be Lindy. The reason being, it's, I said last, the other week that make.com is like a great way to get started with.\r\n\r\n\r\nwith automations and AI agents. Lindy's easier.\r\n\r\n\r\nNikolas Hulewsky (29:43.591)\r\nYep. I've heard a lot about Lindy. What is Lindy? Is it, it's another make-dot, it's Zazappi or Lindy, N8A make, like it's one of those?\r\n\r\n\r\nLiz (29:47.63)\r\nAll right, let me pull it on up.\r\n\r\n\r\nLiz (29:57.654)\r\nIt's one of those. It's one of those, the things they have done and I will share. So this is again, connecting automations. Yep, you can see, okay. Let's make this bigger. Okay, so basically it's the same kind of concept as make.com, N8N, Zapier. It's basically creating a workflow. So we'll just go with some simple ones. Is this the correct?\r\n\r\n\r\nNikolas Hulewsky (30:21.725)\r\nSo why, before we go do a simple one, why do people prefer Lindy to any of these other workflow tools?\r\n\r\n\r\nLiz (30:29.07)\r\nOkay, so Lindy is simple. It's okay. it's simple. They've added a Gentic capabilities. So the difference between a Gentic capabilities are let's see if I can. Okay, this is not a good example.\r\n\r\n\r\nNikolas Hulewsky (30:33.634)\r\nokay.\r\n\r\n\r\nNikolas Hulewsky (30:44.381)\r\nCause you've walked, you've walked me through while you're looking for that, you've walked me through more than a couple of automations and it's not simple. Like it does take time to get up to speed and understand what inputs and outputs and where it flows and et cetera. But you're saying Lindy's people prefer it because it's a simpler UI.\r\n\r\n\r\nLiz (30:48.941)\r\nYes.\r\n\r\n\r\nLiz (30:52.834)\r\nAll\r\n\r\n\r\nLiz (31:04.458)\r\nYeah, well, it's not just the UI. let me first share. Okay. So again, I love things with templates because it's like, why not start and not recreate the wheel? So they have like great templates. And I know we looked at make.com templates, but make.com were usually like a part of a workflow. These are full workflows that actually have outcomes that you might have someone doing a lot of.\r\n\r\n\r\nNikolas Hulewsky (31:13.597)\r\nOkay.\r\n\r\n\r\nNikolas Hulewsky (31:30.813)\r\nSo like pick one of these templates, just say like, does one of these templates do?\r\n\r\n\r\nLiz (31:34.286)\r\nSo lead, let's do lead enrichment. We're gonna demo that one. So basically this is going to find information about your lead. So literally before you would have to have people going out to databases researching years of experience, head count, company HQ, like all of these different parameters from an existing database, pay a ton of money for per lead. Now it just goes off and finds all the relevant information and updates it.\r\n\r\n\r\nNikolas Hulewsky (31:39.698)\r\nOkay.\r\n\r\n\r\nNikolas Hulewsky (31:55.441)\r\nMm-hmm.\r\n\r\n\r\nLiz (32:04.428)\r\nSo for this.\r\n\r\n\r\nNikolas Hulewsky (32:04.669)\r\nOkay, so if you're a business owner and let's say you have, you get a lot of leads coming in or people who are visiting your website, in the past you would have to go out and like manually go and say, who is this person? their LinkedIn profile says this, this is the company that they worked at, this is how big it was, this is what decisions they're making, et cetera. This is a workflow to essentially automate that research time.\r\n\r\n\r\nLiz (32:27.83)\r\nYes. And so this one also can be applied to, sorry, I'm like pulling things up here. This one can also be applied to like if you have a meeting and you're meeting with someone, it'll find information before you meet with them. And so you have like all that information it'll prepare with that. So there's a ton of these like little things that they've actually been thoughtful about and they're not just random.\r\n\r\n\r\ntoday at the templates go. Okay, they're not just random, they're actually useful for business. So I think the\r\n\r\n\r\nNikolas Hulewsky (32:59.027)\r\nAnd the template, the template would be good plug and play. it's like, Oh, I have, I have a CRM hub spot, um, high, you know, high level. I've got Google sheets where I keep a lot of this information. I've got, I'm trying to think of something else. don't know a phone system that has inbound calls. I don't know how to put all of those things together, but with this template, it just walks you through pretty simply. Okay. Now you take this data set and this database and this database and we'll merge them together.\r\n\r\n\r\nLiz (33:06.222)\r\nThank\r\n\r\n\r\nLiz (33:27.498)\r\nExactly. like literally all you're going to need to do is press like click and we'll do one where I haven't set it up yet just to show you so that you can see like how simple it is. But literally all you have to do is like connect your existing tools and you don't even have to worry about some of the API keys because it's like at least for Google you can just do your sign in as if you're signing into something. Yeah. So I'll show it to you in a second. But the other piece that makes this simpler is\r\n\r\n\r\nNikolas Hulewsky (33:47.635)\r\nWow, that's awesome.\r\n\r\n\r\nLiz (33:56.97)\r\nthe agentic capabilities. And so what does that mean? Sorry, I keep losing more. Okay. So like over here, do you see this purple box? Okay. So over here, it has a prompt. This is a prompt basically telling it what to do versus having to figure out, okay, I need to connect this tool and put in my API keys, then figure out what variables pass over. This prompt just basically tells it\r\n\r\n\r\nNikolas Hulewsky (34:02.929)\r\nI don't know, I'm an idiot, so you'll have to tell me.\r\n\r\n\r\nNikolas Hulewsky (34:19.336)\r\nMm.\r\n\r\n\r\nLiz (34:26.082)\r\nI need you to go research the stuff and then put it back in this format and output. And it's pretty simplistic relative to some of the stuff like you would have to do if you were using some of the other tools. Yeah, you can add, absolutely edit it. So blah, blah, blah, blah, blah. Yeah, you can edit it.\r\n\r\n\r\nNikolas Hulewsky (34:38.483)\r\nCan you edit it? Can you like, okay.\r\n\r\n\r\nNikolas Hulewsky (34:44.403)\r\nOkay, so it's not just random, not random, but it's not fixed. can tailor it to my specific use case.\r\n\r\n\r\nLiz (34:48.942)\r\nExactly. they have embedded in here a way to use AI to actually improve your prompts. AI will fill out fields automatically, and then you can set it manually too. So if you want to have it more structured so it's more reliable, you can do that. And I would say that is sort of the thing to consider when you're doing this is like how much level of agency\r\n\r\n\r\nDo you want to give these tools where like if there's something that always you want a certain outcome? You always have sort of fixed processes. You're gonna want a simplistic automation You don't want to have it necessarily be a gentic But if you have a good prompt you can still sometimes get there These ones sort of give it a little bit more freedom to say okay I need to figure out what to do and so when we were talking about reasoning earlier This is now giving it some level of reasoning\r\n\r\n\r\nand decision-making capability as to what part of the internet do I want to go search? What do I need to find? And this is just a simple, simple example, because this is internet research, but this is like, can again be accessing different tools or saying like, okay, within this automation, I need to go and actually access a different automation, which is then getting into some more agentic behavior while it's calling on different tools.\r\n\r\n\r\nNikolas Hulewsky (36:05.843)\r\nSo for tools like Zapier, it's got real network effects because it's got integrations, APIs, templates with a ton of softwares. But this obviously has an easier user interface. Is it as robust as Zapier or is it still, it is, okay.\r\n\r\n\r\nLiz (36:09.902)\r\nMm-hmm.\r\n\r\n\r\nLiz (36:29.848)\r\nSo I would say it's robustive to an extent. So they've done a good job integrating a bunch of existing third party tools, but if you're using some unique software, Zapier has the most integrations with those tools. And when I say integrations, that means like you can easily access them. There are still ways to access those tools. It's just more complicated.\r\n\r\n\r\nin, in, and so I would say again, like if you're using some weird software that, know, only a handful of people in your niche, like it might not be as well integrated. but for the most part, like if you're using the Google suite, if you're using the HubSpot suite, Zoho, whatever, some of the main players that have a lot of these things, like you can use these tools. again, I would just say like, to think differently about agentic behavior versus automation is agent.\r\n\r\n\r\nagentic is like giving that tool the ability to make decisions, to learn and to have some freedom versus automation is literally like process steps. So you can again, make you think of your different levels of worker, like you have a VP versus an intern and an intern is maybe doing data entry and following an SOP versus the VP is making decisions and being thoughtful. Not to say that those are replacing either yet, but.\r\n\r\n\r\nNikolas Hulewsky (37:44.243)\r\nNo, I, yeah, okay. That makes sense to me. So do we wanna build one?\r\n\r\n\r\nLiz (37:50.814)\r\nOkay, so first let me just give a quick little demo of this one because I have it sort of already set up Okay, so they have like settings here which like you can give it some context You can give it memories of things that it'll like only work for just to always remember and this is helpful This is sort of just setting the rules giving like a general sort of these are always gonna happen for this tool Then you have a visualization that just shows a step-by-step. This is again comparable to make comm or Zapier\r\n\r\n\r\nAnd then here's the tasks. So this is where you can within this, just tell it to do things. And again, like you can automate this so you're not prompting it in here, but this is just an easy way for demoing.\r\n\r\n\r\nNikolas Hulewsky (38:30.931)\r\nSo is the tasks kind of like an AI window where it's like, you're just, hey, this is what I want to do. And it sort of spits out.\r\n\r\n\r\nLiz (38:39.69)\r\nExactly. Exactly. That's sort of like your chatter. So, and it gives you, know, again, Lindy has thought really well on how to get people started. And so it gives you a little bit of problems on what you need to provide here. But if you want to see, we'll switch back over here in a second to see how it's flowing and what's triggering it. So again, the message received is going be from the task or a new row added within a spreadsheet. So I've set up a little, you see, actually, hold on. I have to reshare. think, let me reshare because\r\n\r\n\r\nNikolas Hulewsky (38:42.301)\r\nVery cool.\r\n\r\n\r\nLiz (39:09.934)\r\ntoggle between these two. okay, great. You see the spreadsheet. Okay. So this is just a simple spreadsheet I use for the demo. So what we're going to do here, lead enrichment. So we're going to put in my name and see what info it finds about me, because basically what this is going to do is internet research. So right now it's showing us, yeah. So it's going to find, so it already figured out, okay, that's my icon. So\r\n\r\n\r\nAll right, so it's going, it's going. And as you can see here, there was nothing here before and it'll pop up in a second. So if we just give it a sec to run.\r\n\r\n\r\nNikolas Hulewsky (39:47.123)\r\nOkay, that's crazy. you're not giving it a data set to look up information on you. It's going out to the web.\r\n\r\n\r\nLiz (39:54.828)\r\nYep, and I barely did anything. All I did was just set it up with the Google Sheet. That's all I did to set it up.\r\n\r\n\r\nNikolas Hulewsky (40:02.311)\r\nAnd you just put your name. It didn't even have a name to go off of. You put it in the task.\r\n\r\n\r\nLiz (40:05.809)\r\nYes, exactly. So as to figure out when we'll put your name, we can put your name and do a few others as well just to show that it's not biased by me. All right, not yet. I think we have to wait for it to show up here.\r\n\r\n\r\nNikolas Hulewsky (40:11.25)\r\nOoh.\r\n\r\n\r\nNikolas Hulewsky (40:18.835)\r\nBut I could also upload or through an automation, have it go to my CRM to pull names. Okay.\r\n\r\n\r\nLiz (40:26.634)\r\nYes. Okay. For some reason, why did this not hold on? okay. Updating wrote. That's why. Okay. Cause it's like, didn't show up in my row. Okay. So first it gave the output here. So it said current role. Okay. This is all accurate from what I'm glancing. Yep. So some of this is like from my social media and that's actually interesting because usually you have to like use scraper tools to go and like find information about people and they're\r\n\r\n\r\nNikolas Hulewsky (40:42.417)\r\nWow.\r\n\r\n\r\nNikolas Hulewsky (40:47.559)\r\nHold on, show me the prompt you set again. What does it say?\r\n\r\n\r\nLiz (40:51.342)\r\nSo all I did was I didn't even put a prompt. literally put my name in the top. Yep. But if we dig a bit deeper in here, we can see like what it is providing. And those aren't even complex prompts. Like it's just saying using the information found about the contact, find the years of experience. So there's probably a bunch of stuff going in the background. It's using a model three it's using 3.5, not even 3.7 for Claude. You can change the models.\r\n\r\n\r\nNikolas Hulewsky (40:55.869)\r\nJust your name. Holy crap. Okay.\r\n\r\n\r\nLiz (41:18.458)\r\nbut yeah, you can even see, and again, change the prompts and change the search engine. So if there's another search engine like Bing or I don't know why I even use Bing, except for the LLMs. But yeah, so basically it's structured in the data into, all these little, you know, all I did was literally type in this, these titles and that was all the work I did.\r\n\r\n\r\nNikolas Hulewsky (41:29.969)\r\nMaybe they want to, maybe they like being.\r\n\r\n\r\nLiz (41:46.114)\r\nSo to get this set up and find information, yeah, and it gave my Twitter profile and this was accurate. So here, do you me to do you or we can do? All right, think Nick or doing Nicholas, you're usually Nick on the internet, so.\r\n\r\n\r\nNikolas Hulewsky (41:54.373)\r\nYeah, I want to see what it says about me.\r\n\r\n\r\nNikolas Hulewsky (42:00.827)\r\nI don't know, whatever one's gonna get better results.\r\n\r\n\r\nLiz (42:03.731)\r\nAll right, it's spelled true last name, right? Okay, let's see what it finds.\r\n\r\n\r\nNikolas Hulewsky (42:10.193)\r\nI can't see because this green is so small, but I think you spelled my last name right.\r\n\r\n\r\nLiz (42:11.864)\r\nHope, I think so. Zoom in a little, yeah. All right.\r\n\r\n\r\nNikolas Hulewsky (42:18.151)\r\nYeah, it's not your fault. I have a little monitor up here. Man, so this would be fantastic for prospecting. You didn't even have to build this. It's just a template that's in there.\r\n\r\n\r\nLiz (42:25.942)\r\nYes, yes. So exactly. So, you know, the friction to start building these things is becoming substantially less. And I know I keep alluding to this, but MCPs are also really supporting that effort. And again, we'll talk about that maybe next week, but the ability to just basically put in a prompt and then it goes and does stuff. Like, I think these all are going to converge. I don't know if chat GPT will ever get.\r\n\r\n\r\nto this level of agenticness because they're more focused on consumer versus business use cases. But I mean, even building some of the stuff I've been building, I'm like, man, like my tool just became obsolete or my automation became obsolete because these guys are getting so good at just building the stuff in the background. So again, if you're a business owner, this is really good. The only downside, okay, let's see what this is and I'll explain the downside after. So yeah, this looks accurate.\r\n\r\n\r\nokay, so this is inaccurate, where you're located. I don't know how much you've shared. It says you're in Texas. I think that's because it's probably an info on Chris.\r\n\r\n\r\nNikolas Hulewsky (43:24.925)\r\nWhat does it say?\r\n\r\n\r\nNikolas Hulewsky (43:32.499)\r\nI used to live in Texas, but not in Texas, no.\r\n\r\n\r\nLiz (43:35.704)\r\nDid you go to UCLA and USC? Okay.\r\n\r\n\r\nNikolas Hulewsky (43:38.46)\r\nI did.\r\n\r\n\r\nLiz (43:43.288)\r\nYeah.\r\n\r\n\r\nNikolas Hulewsky (43:43.345)\r\nMy wife is not gonna like this.\r\n\r\n\r\nNikolas Hulewsky (43:48.819)\r\nShe's just like, I don't like having my information on the internet.\r\n\r\n\r\nLiz (43:51.372)\r\nYeah. it just failed. Yeah. So this, so again, like, as we were saying, there's some level of hallucinations and some inaccuracies and, but again, like in databases and humans, like doing that research, like there is a level of error, right? So,\r\n\r\n\r\nNikolas Hulewsky (43:53.362)\r\nWow.\r\n\r\n\r\nNikolas Hulewsky (44:08.957)\r\nWhat you, you brought up a really interesting point because I wouldn't have even thought of Lindy doing these types of things. like just to do this, you didn't need to enter your Google, Google API or your CRM and from like, it's just going out and executing on that task. I would have thought, that would be something you do within chat GPT or quad or Gemini or perplexity or any of these.\r\n\r\n\r\nother LLMs that are able to actually go and search the web. But that's a function within Lindy that's like, this is a best in class function within Lindy. And it's interesting to see now these LLMs changing so much. for example, Canva came out this last week and they came out with a big update and I don't even know anything about Canva, but I just saw somebody come out and we're like, Hey, the development tools now within Canva, like its ability to help you code is incredible.\r\n\r\n\r\nLiz (44:54.89)\r\nMm-hmm. Yep.\r\n\r\n\r\nNikolas Hulewsky (45:08.465)\r\nI didn't even think, I thought Canva was just like, let's make pictures. And now you're telling me it's as good of a coding co-pilot as anything else out there, right? Like that's fascinating to me that there are individual use cases with each one of these that you're not even considering. So there are the general models, like we're talking about Claude, Gemini, OpenAI, ChatGPT, et cetera. But then there are these like specific use cases where all of a sudden, Lindy's my go-to for doing research on people and Canva is my go-to for coding and...\r\n\r\n\r\nCursors might go to for building websites. It's hard to keep up with like, okay, which one of them are the best in each one of these specific areas.\r\n\r\n\r\nLiz (45:45.518)\r\nSo I would say the only downside and the thing I've started, it's funny because I'm like jaded now where it's like again, I'd have to probably hire, you know, someone for 40 to I don't know, $60,000 for administrative work on a yearly basis. And I'm like, oh my gosh, my credits are going, I have to now upgrade to the $200 month plan or whatever. And it's like, literally the comparison is pretty astronomical in savings of a human doing this.\r\n\r\n\r\nNikolas Hulewsky (46:04.019)\r\nAll right.\r\n\r\n\r\nNikolas Hulewsky (46:11.729)\r\nRight. Right.\r\n\r\n\r\nLiz (46:13.59)\r\nSo that is the one thing to consider though, because like down here you can see credits and like I've been starting to keep an eye on this stuff because I use this stuff a lot. And I scrape a ton of data. And so I get, I hit limits and have to constantly upping my credits, tokens, operations, whatever the tool calls it. And so I've been doing like cost comparison. I don't yet have perfect apples to apples, but I would say like Lindy and Zapier are going to be more on the somewhat pricier side.\r\n\r\n\r\nmake is still like relatively okay, although I've been eating up operations and then any N which at some point I'll show it's just very intimidating to folks. But that actually there's a way to do it where you can scale to the sky for nothing because you it's okay.\r\n\r\n\r\nNikolas Hulewsky (47:00.575)\r\nSo from a cost standpoint, what does it cost? How much are you spending on these models a month? Not from a usage-based standpoint, not just like, it's $20 a month for OpenAI's top tier.\r\n\r\n\r\nLiz (47:02.542)\r\nYeah.\r\n\r\n\r\nYes.\r\n\r\n\r\nLiz (47:13.76)\r\nYeah. I mean, okay. So that's like a moving target. I've had months where I've made a lot of mistakes and I would run up an API bill because I just did auto up, and it kept charging me and I didn't realize I had defaulted on one of my automations, like, that was really expensive. And that costs me like, you know, a couple thousand dollars when I didn't realize it. So that was a miss. Yeah.\r\n\r\n\r\nNikolas Hulewsky (47:30.493)\r\nMmm.\r\n\r\n\r\nNikolas Hulewsky (47:36.861)\r\nDay! Couple grand?\r\n\r\n\r\nLiz (47:38.798)\r\nThat was a mistake. And that was like, again, I was using 03 for like a very simplistic thing and it was like thousands and thousands of spreadsheet rows. So that was like human error. You can do these well, I would say like a couple hundred dollars a month max if you have like a large data set. So again, this is like relatively speaking, not that expensive considering what you would compare it to human, not that expensive. And models are just the costs are going down so dramatically every like month.\r\n\r\n\r\nNikolas Hulewsky (47:44.179)\r\nMm-hmm.\r\n\r\n\r\nLiz (48:08.64)\r\nSo unless you're again doing something where you have millions of rows of, you know, that you need to figure out data on, which is going to be enterprise use cases, like you shouldn't be too, too worried unless like you are very cash strapped. but again, like it is reasonable. just am starting to, you know, start to take a look because again, like it says 6,000 credits, it's a little bit misleading because what is 6,000 credits? What is one credit?\r\n\r\n\r\ninclude it's not just like one flow. I think, let's see, we just used, let's even see if it shows, oops, I'll show my bill, but okay. So like we just used for these, you can see how much it's using. So for to do research on you, you cost a lot. It was 118 tokens. So, you know, well, I have a total, I started with 5,000 and just to do the research on you, it cost 118 tokens.\r\n\r\n\r\nNikolas Hulewsky (48:55.356)\r\nHow much is the token?\r\n\r\n\r\nLiz (49:06.049)\r\nSo.\r\n\r\n\r\nNikolas Hulewsky (49:06.192)\r\nSo for 5,000 tokens, how much did it cost to do 5,000 tokens?\r\n\r\n\r\nLiz (49:08.884)\r\n5,000, sorry. That I think was, let's see.\r\n\r\n\r\nI don't even know what level I'm on here.\r\n\r\n\r\nNikolas Hulewsky (49:19.665)\r\nI'm just trying to get like a, okay, each token costs a tenth of a cent or something.\r\n\r\n\r\nLiz (49:24.174)\r\nOkay, so for 6,000 credits, it's 60 bucks a month. 400 credits you can do it, or 400 credits for free. then, yeah, sorry, token and credit, I'm using interchange operation and make, like they all call them different things, which is confusing and none are like equal. So that's also annoying. But for a business use case, like 30,000, like I could see in a business use case, eating those up pretty quickly. Again, with like all the different things you're gonna want to do.\r\n\r\n\r\nNikolas Hulewsky (49:30.557)\r\nAnd as a credit of token.\r\n\r\n\r\nLiz (49:52.588)\r\nAnd then they have custom pricing. again, I would say like choose the use cases to get started that are going to be most impactful for your business. But again, like doing lead research, doing anything on the revenue side is probably going to be helpful or, you know, maybe on, customer calls or, you know, maybe just the stuff you really hate doing, like billing or expenses.\r\n\r\n\r\nNikolas Hulewsky (50:13.523)\r\nSo 60,000 tokens for 60 bucks is a cent, one cent per token. it costs you a buck to do your background analysis on me, or a buck 20.\r\n\r\n\r\nLiz (50:17.986)\r\nYeah. Yeah.\r\n\r\n\r\nLiz (50:23.276)\r\nYeah. So then, yeah. So then you have to also then start thinking to compare that to databases you have access to. And it's funny because in some cases I'm like, man, now I miss SAS. I miss my subscription fee, even though these are like subscription usage. So, you know, I think the winners are going to be like open source. They're still a bit clunky, but like they're going to be competing with these guys. So it's really like the ease of use, the UI that you're paying for, because like you could\r\n\r\n\r\nNikolas Hulewsky (50:29.011)\r\nHmm.\r\n\r\n\r\nNikolas Hulewsky (50:35.845)\r\nYeah.\r\n\r\n\r\nLiz (50:51.458)\r\nget to those outcomes, it just requires a little bit more effort and time to do it for free. So again, like these are all trade-offs. I would say like just start doing it because it will have a real impact for your business and don't get Pennywise here and pound or dollar foolish or whatever. But I mean, it will have, it'll drive impact. yeah, Lindy. Yep. Yep.\r\n\r\n\r\nNikolas Hulewsky (51:08.157)\r\nYeah, yeah, for sure. Cool.\r\n\r\n\r\nNikolas Hulewsky (51:15.059)\r\nCool, I love it. All right, so Lindy, everyone should go check out Lindy. Go make your first automation. One cent a token. Well, I guess it probably gets cheaper as you go to the higher tiers, but it's awesome. Thank you, Liz. It was a good week. Okay, we'll talk next week.",
  "metadata": {
    "duration": "",
    "date": "2025-04-30",
    "platform_source": "Google Drive"
  }
}