{
  "episode_number": "171",
  "episode_title": "AI SERIES: 14 - How to Avoid Massive AI API Costs with Michael Greenberg",
  "guest_name": "Michael Greenberg",
  "business_name": "Digital Operations Playbook",
  "transcript": "ï»¿Nikolas Hulewsky (00:00.996)\r\nMichael Greenberg, welcome back. I am freaking stoked to learn AI from the Jedi master himself. You are a serial entrepreneur. have multiple businesses. You have a ghost writing agency. You have an automation agency. have, what am I missing here? Offshore podcast. There you go. Podcast booking. And you are, you're an AI guru. So I wanted to learn from you. How are you using AI in your business? Here's my first question though. What models do you use and for what?\r\n\r\n\r\nMichael Greenberg (00:15.118)\r\nPodcast booking that's the that's my favorite right now. It's a star\r\n\r\n\r\nMichael Greenberg (00:23.874)\r\nThanks.\r\n\r\n\r\nMichael Greenberg (00:30.75)\r\nOoh, okay. So you asked me this two weeks ago. I'd be like, all I do all day is three mini. And then occasionally if I'm doing some creative writing, I'll use Claude with extended thinking. and one pro when I need like a real thought partner, but Gemini 2.5 pro very recently came out and I love it. It's super fast. It's very smart.\r\n\r\n\r\nMy team loves it. We are already starting to deploy it and replace it inside some of our research tools because it is just so much better with the large context windows.\r\n\r\n\r\nNikolas Hulewsky (01:11.43)\r\nOkay, can you help me understand? I don't fully understand. People have explained it to me, but I'm still an idiot. Like when I go to ChatGPT, all right, and I asked the question, there are more than one model you can choose from. You can choose 4.5, which is in beta. You can choose 4.0, you can choose 3.5, and then you can choose these ones that you named, 0.1, 0.1 mini. There's probably some others that I'm like forgetting at the moment. I get the like 3.5, 4.0, 4.5.\r\n\r\n\r\nMichael Greenberg (01:16.024)\r\nYeah.\r\n\r\n\r\nMichael Greenberg (01:32.088)\r\nYeah.\r\n\r\n\r\nNikolas Hulewsky (01:39.866)\r\nBut like, do you use the O1 and the O1 minis for? I don't understand this.\r\n\r\n\r\nMichael Greenberg (01:44.971)\r\nyeah, good question. So,\r\n\r\n\r\nSo the big difference here is one is a set called reasoning models and that's going to be your own ones or 2.5 pro with Gemini extended thinking or thinking on Claude and Grok has a thinking mode as well. Reasoning models spend some time going over the problem before they give you a solution. And so like if you're writing code.\r\n\r\n\r\nNikolas Hulewsky (02:00.933)\r\nwith Claude.\r\n\r\n\r\nMichael Greenberg (02:17.888)\r\nor you're solving logic problems or you need reasoning, any sort of logical processing, those models are going to be much, much better. They're also way more expensive to\r\n\r\n\r\nNikolas Hulewsky (02:28.165)\r\nOkay, so if I was negotiating the sale of a business and I was like, here's the set of facts, here's what they offered me in the LOI, I wanna counter back to them with X, Y, and Z, I would use O1. I wouldn't use necessarily 4.0 or 3.5.\r\n\r\n\r\nMichael Greenberg (02:46.048)\r\nyeah, you would want to use a reasoning model, especially if it has math involved. like when you heard about six months ago, people were like, AI can't do math. And now they're like AI is the best at math. The big difference is reasoning models, which started with one and one pro and one mini has now gone on to three four is about to release.\r\n\r\n\r\n04 mini at least is about to release and 03 the full version is what they use with chat GPT deep research now to produce those amazing results as well as I think operator the thing that uses the computer for you. I think that also uses 03. So these are the models that are getting smart enough to really replace people in some of these specific tasks.\r\n\r\n\r\nNikolas Hulewsky (03:26.191)\r\nYep, yep.\r\n\r\n\r\nNikolas Hulewsky (03:34.885)\r\nOkay, so you said, I wanna look at these really quick. So 40, 4.5. So what is, you, bleh, bleh, bleh. I'm like tripping over myself. 03 Mini is the best reasoning model.\r\n\r\n\r\nMichael Greenberg (03:50.63)\r\none row is probably the best. three mini high. So I pay the $200 a month on and I am, I am only using three mini high and one pro. I do not use any of the other models.\r\n\r\n\r\nNikolas Hulewsky (03:54.406)\r\nPro. Okay. How do you know which one of these to use?\r\n\r\n\r\nNikolas Hulewsky (04:11.013)\r\nI'm gonna share my screen real quick. Yeah, I'm gonna share my screen really quick. All right, so if I'm here and I'm in chat GPT, you open a new window and I come up here, because this is where you actually select which model you're gonna use, you do the dropdown, and I see all these models, right? GPT-40.\r\n\r\n\r\nMichael Greenberg (04:23.054)\r\nYeah.\r\n\r\n\r\nI skip over 4.0 only for if I'm maybe if I'm doing image generation, I'll use 4.0.\r\n\r\n\r\nNikolas Hulewsky (04:32.041)\r\nyeah, because it looks too, my gosh, the image generation's fantastic, by the way. Anyways.\r\n\r\n\r\nMichael Greenberg (04:36.611)\r\nI spend at least 30 minutes making images of my dog in like different costumes and portraits every day.\r\n\r\n\r\nNikolas Hulewsky (04:41.221)\r\nIt's so funny. It's so funny. Your dog. It's so good.\r\n\r\n\r\nMichael Greenberg (04:45.484)\r\nYeah, I've got a Twitter post coming where it's like, here's my dog in 30 different portraits.\r\n\r\n\r\nNikolas Hulewsky (04:50.928)\r\nOh my gosh, the step brothers, you and your dog in sweaters. you need to, you need to. Okay, so what do you use 4.54?\r\n\r\n\r\nMichael Greenberg (04:55.701)\r\nI'm going to get that one now. We've like, yeah.\r\n\r\n\r\nMichael Greenberg (05:03.692)\r\nI\r\n\r\n\r\nNikolas Hulewsky (05:05.133)\r\nOkay, so 4.5 says, if you're listening to this, I'm hovering over 4.5, it says good for writing and exploring ideas. But then you said the reasoning models are actually better than 4.5. So why would I use 4.5 if I wanted to use better reasoning?\r\n\r\n\r\nMichael Greenberg (05:10.072)\r\nsays.\r\n\r\n\r\nMichael Greenberg (05:20.387)\r\nYeah.\r\n\r\n\r\nSo this when they say writing and exploring ideas they're talking about like creative philosophical stuff more. You know look I'm a B2B guy. I'm like I'm in B2B. I need logic and reason I'm writing most of my content is one or two steps away from a business case. And so I need a certain I think at least for me and because I'm kind of a boring analytical guy in my head.\r\n\r\n\r\nNikolas Hulewsky (05:36.292)\r\nYeah.\r\n\r\n\r\nMichael Greenberg (05:52.25)\r\nThe reasoning models really get me a lot better and they're a lot smarter. Yep.\r\n\r\n\r\nNikolas Hulewsky (05:55.724)\r\nOkay, okay. Give me, give me 30 seconds.\r\n\r\n\r\nNikolas Hulewsky (06:13.317)\r\nOkay, so creativity where it's like, I wanna write a song or I want these words to rhyme or I wanna figure out a way to incorporate this with this, that's where 4.5 is gonna really work. But anything logic based, contract negotiation, business bottle, trying to figure out a business bottle, et cetera. Interesting.\r\n\r\n\r\nMichael Greenberg (06:29.582)\r\npretty much everything business related. and that's, I think that's what I see. And this might be the secret hack is like everyone I know who's seriously using AI for business, for writing all that stuff, they are exclusively paying for the most expensive models they can. And they're only using those. So there's a big difference between like, if you're talking to 4.0, it's kind of dumb compared to 03 mini high or just 03 mini.\r\n\r\n\r\nNikolas Hulewsky (06:55.983)\r\nOkay, so there's 01, 03 mini, 03 mini high, 01 pro mode. even just looking at these, I wouldn't know like, this one is the best. Cause there's no like order to them in my mind.\r\n\r\n\r\nMichael Greenberg (07:02.582)\r\nYeah. So.\r\n\r\n\r\nMichael Greenberg (07:09.378)\r\nWell, O1 Pro, it does say best at reasoning. So that one, it does say that is the best. It also takes two to three minutes for it to respond in most cases.\r\n\r\n\r\nNikolas Hulewsky (07:13.636)\r\nOkay.\r\n\r\n\r\nI hear, wow, okay, you didn't have to call me out like that, Michael, but okay.\r\n\r\n\r\nNikolas Hulewsky (07:25.317)\r\nokay, so these aren't quick queries. These are, because they're thinking through it. These are logical responses.\r\n\r\n\r\nMichael Greenberg (07:30.466)\r\nYeah, so 03 mini high, you're going to be under 30 seconds for most responses, which is why it's probably the one I use most often because it's a lot smarter than 03 mini, but it doesn't take a lot longer to answer. 01 pro though, it's slow.\r\n\r\n\r\nNikolas Hulewsky (07:44.453)\r\nInteresting.\r\n\r\n\r\nNikolas Hulewsky (07:48.431)\r\nWhat about 01?\r\n\r\n\r\nMichael Greenberg (07:50.08)\r\nO1 is faster but there's no reason to use O1 if you have O3 mini high.\r\n\r\n\r\nNikolas Hulewsky (07:56.976)\r\nDude, I mean, we have an actual conversation queued up here of things that I thought were fascinating.\r\n\r\n\r\nMichael Greenberg (08:00.704)\r\nYeah, I could talk about these models like and just go back and forth all day. We\r\n\r\n\r\nNikolas Hulewsky (08:04.163)\r\nNo, this is amazing. This is why I have people on because I'm trying to figure out how the freak do I use these things. I feel like a neanderthal every time I go to Chachi Buti and I'm like, okay, there's seven different models. I'll just choose for again. so wait, okay, while you're pulling that up, let me ask you this of the reasoning models that you named. So the O ones for whatever, Chachi Buti and then the Gemini model that you talked about and then the Claude.\r\n\r\n\r\nMichael Greenberg (08:16.974)\r\nSo you want to see something scary?\r\n\r\n\r\nMichael Greenberg (08:23.01)\r\nYeah.\r\n\r\n\r\nNikolas Hulewsky (08:33.795)\r\nmodel that you talked about. can't remember the names of them, but those are the three that I remember you mentioning. Which ones are the fastest?\r\n\r\n\r\nMichael Greenberg (08:37.922)\r\nYeah.\r\n\r\n\r\nOoh, so your fastest models are going to be Gemini. Just across the board like Grok is pretty fast too, but in terms of like models that we will actually use in like production use cases where somebody needs a fast response that is intelligent, it's going to be Gemini 90 % of the time.\r\n\r\n\r\nNikolas Hulewsky (09:01.613)\r\nIf you're negotiating for your life savings, like everything is on the line, Family legacy is on the line. Which one of those models would you use?\r\n\r\n\r\nMichael Greenberg (09:08.227)\r\nYeah.\r\n\r\n\r\nCan I pick a model that's not out yet? That we know is coming in the next like month?\r\n\r\n\r\nNikolas Hulewsky (09:14.277)\r\nOkay, first pick a current model and then you can tell me what the one coming is.\r\n\r\n\r\nMichael Greenberg (09:18.326)\r\nOkay, so I'm probably going to pick 2.5 Pro, Gemini 2.5 Pro. it's fast enough and it has the context window where it can deal with a long negotiation.\r\n\r\n\r\nNikolas Hulewsky (09:23.511)\r\non Gemino.\r\n\r\n\r\nNikolas Hulewsky (09:34.021)\r\nSo why is speed that important though? Like I would think you take as much time as you need, right?\r\n\r\n\r\nMichael Greenberg (09:37.824)\r\nSo speed is less important. Context window is very important. Two point Gemini models have context windows. So like they remember in the conversation five or 10 times more than other models.\r\n\r\n\r\nNikolas Hulewsky (09:49.562)\r\nYeah. Well, I was just explaining this to somebody yesterday. So I'll tell you my dumb man's explanation of this. But if, I was trying to buy a business, I would go to somebody who I knew was a business buying expert and I would ask for their advice. Right. But in order for them to give me specific advice, they'd have to learn a lot about me. They'd have to learn like, what are my skillset? How much money do I have? What industries do I know and not know? What's my risk appetite, et cetera. And so I have to tell them all those things. And then once they get that information.\r\n\r\n\r\nMichael Greenberg (09:57.004)\r\nYeah.\r\n\r\n\r\nNikolas Hulewsky (10:19.621)\r\nwhoop, then they give me the answer. So that person who has the experience of buying businesses, that's like all these underlying models. They just went and trained on generic data and that's great. The context that I gave him are these context windows that we talk about, right? And these context windows vary. Chatchity BT has like 120,000 tokens, Gemini goes to a million and Claude is at, I think 200,000. It's like, I think those are the right numbers.\r\n\r\n\r\nMichael Greenberg (10:31.117)\r\nYeah.\r\n\r\n\r\nMichael Greenberg (10:46.051)\r\nYeah.\r\n\r\n\r\nNikolas Hulewsky (10:47.459)\r\nSo yeah, to your point, it's like almost 10X of chat GPT and it's five times what Claude is. So what you're saying is in a negotiation, you can give it a bunch of context that it can remember and then help you sort of craft your negotiation.\r\n\r\n\r\nMichael Greenberg (11:02.05)\r\nYeah, and it's just about as smart as the smartest model available right now.\r\n\r\n\r\nNikolas Hulewsky (11:06.553)\r\nSo one of the things I've heard though, and then I'm going to ask you which one's coming out that you would use, is that just because you can accept a ton of context doesn't necessarily mean it knows how to synthesize it well enough to give you the best answers. So in some instances, it's like more context isn't necessarily better answers.\r\n\r\n\r\nMichael Greenberg (11:28.312)\r\nSo that is both true and untrue. It is true in the sense that if you stuff it with more and more information, it will work worse because it has more information to sort through or to predict from.\r\n\r\n\r\nBut it is also true that it will remember more effectively. So if you are only using a hundred thousand tokens, that would be almost all of chat GPT, but it would only be a tenth of Gemini and Gemini will have better recall over that information compared to chat GPT.\r\n\r\n\r\nNikolas Hulewsky (12:07.907)\r\nOkay, interesting. All right, so Gemini 2.5, tell me what's the model that's gonna come out that you're like, that's the one I would use.\r\n\r\n\r\nMichael Greenberg (12:15.054)\r\nI would use 03 Pro. So 03 is the model from OpenAI and then Pro Mode is going to have it think really, really long. And that's going to make it way smarter than all the other models.\r\n\r\n\r\nNikolas Hulewsky (12:18.212)\r\nNikolas Hulewsky (12:30.627)\r\nand when it's thinking really, really long, is the context window the same?\r\n\r\n\r\nMichael Greenberg (12:35.17)\r\nYeah, but context window gets shorter as it thinks longer because like it's you know, like when you can only hold us so much so.\r\n\r\n\r\nNikolas Hulewsky (12:46.109)\r\nwindow gets shorter as it thinks longer. Okay so you said it\r\n\r\n\r\nMichael Greenberg (12:49.366)\r\nSo like a reasoning model is going to have a shorter context length than a non reasoning model in most cases. Gemini is kind of the exception to this because Google is the one who invented all of this technology. Lest we all forget, Google invented the transformer, which is the core technology revolutionizing all of this AI.\r\n\r\n\r\nNikolas Hulewsky (13:03.439)\r\nso forth.\r\n\r\n\r\nNikolas Hulewsky (13:11.397)\r\nI mean, Google invented AI and sort of motivated Elon Musk to say, hey, we need to have something to counter them, which is kind of where OpenAI came out of. But for OpenAI, for example, is the context window going to stay the same for this new model?\r\n\r\n\r\nMichael Greenberg (13:13.39)\r\nYou\r\n\r\n\r\nMichael Greenberg (13:28.182)\r\nIt will probably get longer. So context window pretty consistently gets longer model generation to generation because we learn new techniques to optimize the model and to improve context. I expect it will probably not move a ton. Honestly, like I think they will probably release an update in the next six months where it is. we now have a million token context window.\r\n\r\n\r\nNikolas Hulewsky (13:30.243)\r\nAlso, they...\r\n\r\n\r\nNikolas Hulewsky (13:35.744)\r\nwhat?\r\n\r\n\r\nWhat do you think it'll go to?\r\n\r\n\r\nMichael Greenberg (13:55.714)\r\nbecause I think the papers are already out there and it's more an implementation thing for them is my guess.\r\n\r\n\r\nNikolas Hulewsky (14:02.206)\r\nThe papers you mean like the white papers that theorize how they would actually make the context windows larger? Okay.\r\n\r\n\r\nMichael Greenberg (14:06.538)\r\nYeah, and like competitors have done this, they have published on it. So it's not like it's a secret anymore.\r\n\r\n\r\nNikolas Hulewsky (14:13.305)\r\nYeah, that has been one of the interesting things to see is like, Grock comes out with a really good image generation and you can actually edit the photo. And then three days later, open AI is like, check out four where we can now generate really, really good copy or a deep seat comes out. then chat GPT is like, check out deep research and operator. Like it's pretty cool to in real time to see they've got this stuff. There's it's in a sandbox at the moment, but once somebody releases something close to it, they're like, okay, we got it.\r\n\r\n\r\nMichael Greenberg (14:23.042)\r\nYeah.\r\n\r\n\r\nMichael Greenberg (14:38.67)\r\nYeah.\r\n\r\n\r\nNikolas Hulewsky (14:43.321)\r\nThey tested it. All right, let's go. can, we can get out now.\r\n\r\n\r\nMichael Greenberg (14:45.516)\r\nIt's yeah, we're in as long as we're not the first one out the door. We're not the one responsible for the havoc that this wreaks.\r\n\r\n\r\nNikolas Hulewsky (14:50.864)\r\nYeah. So if you're going to be using these reasoning models, do you want to give it like a lot of context? I don't mean a lot of context in the sense of like, if it's 120,000 token window, you want to give it 100,000 tokens. That's not what I mean. But, know, a lot of people use four or 4.5 and just ask it a question like, Hey, how would I go about finding the best business to buy in Minnesota?\r\n\r\n\r\nand then it'll be a thought partner to like go back and forth, right? But that's not a lot of context. With the reasoning models, you probably don't want to ask it that type of question. You want to ask it something very detailed that you have a lot of information around that you can then glean answers through.\r\n\r\n\r\nMichael Greenberg (15:35.99)\r\nYeah, so if I'm not like, let's say I am not any sort of AI expert and I don't write like write prompts as a paid professional. What am I going to do instead? Well, first I am going to go and apply for an anthropic API key. And so Anthropic is the company who makes Claude. And if you have an API key,\r\n\r\n\r\nNikolas Hulewsky (15:51.237)\r\nI know, tell me.\r\n\r\n\r\nMichael Greenberg (16:05.204)\r\nOr and I think you get access to this just by applying you can get access to their console and I'm going to share my screen if that's all right. And just show off here.\r\n\r\n\r\nNikolas Hulewsky (16:12.505)\r\nYeah. I love prompts. I love prompts right now. I just wrote my newsletter this week about the four C's of prompting and like people don't realize how important it is to ask the right question. Otherwise you're not going to get the right answer.\r\n\r\n\r\nMichael Greenberg (16:27.958)\r\nYeah. so what let's make a prompt. What's a so there's only really like eight things that an LLM can do, maybe less depending on how you count through them. Let's say that we want to like analyze some text.\r\n\r\n\r\nand so let's say, know, I've been writing a book on some of this stuff. And so I often want like a writer's assistant analyze this chapter of a book, keeping in mind the rest of the book below.\r\n\r\n\r\nMichael Greenberg (17:11.692)\r\nand then act as an expert writers assistant and digital operations professional because digital operations is my thing. With a background in consulting and project management. So I'm calling out like some skill sets and I've got this thing open. You can see I want to generate a prompt.\r\n\r\n\r\nAnd then I'm gonna say.\r\n\r\n\r\nNikolas Hulewsky (17:41.638)\r\nSo just for the Neanderthals out there like me, what he's doing is within any of these models, ChatGPT has this, Claude has this, there's an ability for them to link to other softwares. And that ability to link to other softwares is called an API key. And when you go and you're linking it to other softwares, you also need to tell OpenAI or Claude how it should interact. You're essentially writing a prompt. So what Michael's doing is he's writing the prompt. He's in this...\r\n\r\n\r\nI can't remember what it's called, Studio.\r\n\r\n\r\nMichael Greenberg (18:12.428)\r\nYeah. So they call this a workbench. and this is, so what I'm doing is I, there's an AI behind this thing and I'm telling this AI, I want it to write a prompt that does this and acts like this. And then let's say we want, did I say analyze the chapter of this book? And then let's say provide detailed feedback in a SWOT format.\r\n\r\n\r\nBecause strengths, weaknesses, opportunities, threats is a...\r\n\r\n\r\nNikolas Hulewsky (18:47.973)\r\nYeah, tariffs, tariffs, sorry, no, it's tariffs, I'm just kidding.\r\n\r\n\r\nMichael Greenberg (18:51.948)\r\nOkay, that's the economic version. And then I'm gonna say, I wanna use this with thinking enabled. So I'm gonna use this with reasoning models. And then I'm hit generate.\r\n\r\n\r\nNikolas Hulewsky (19:04.995)\r\nIf I wanna use this, how much does this cost a month?\r\n\r\n\r\nMichael Greenberg (19:07.608)\r\nThis is free. Yeah. So what I'm showing you now is free. And so now it is.\r\n\r\n\r\nNikolas Hulewsky (19:08.901)\r\nThis is free.\r\n\r\n\r\nNikolas Hulewsky (19:13.381)\r\nOkay, so what, I just see a bunch of text. What the freak is it doing?\r\n\r\n\r\nMichael Greenberg (19:17.356)\r\nSo it has now written this prompt like a professional prompt engineer. so, OK, does this fit the four Cs? Let's find out.\r\n\r\n\r\nNikolas Hulewsky (19:24.293)\r\nOkay, so just, again, again, again, people who are listening, he wrote a prompt that was probably three sentences.\r\n\r\n\r\nMichael Greenberg (19:32.384)\r\nYeah, maybe like two or three, yeah.\r\n\r\n\r\nNikolas Hulewsky (19:34.053)\r\nOkay, two or three sentences. This just spit out, I don't know, two pages worth of a prompt. Holy crap.\r\n\r\n\r\nMichael Greenberg (19:40.748)\r\nYeah, this is a and so you can see here now it says chapter and it's using this little like code like notation so that way it knows where the chapter is and then it says OK do SWOT and we're going to go through and it tells you it tells exactly what each piece of SWOT is in relation to like pinpoint the areas of the chapter so it's rephrasing what SWOT should be for a book.\r\n\r\n\r\nNikolas Hulewsky (19:44.409)\r\nThat's it.\r\n\r\n\r\nNikolas Hulewsky (19:49.22)\r\nMm-hmm.\r\n\r\n\r\nNikolas Hulewsky (20:03.629)\r\nMichael Greenberg (20:10.466)\r\nchapter instead and then it's saying detailed feedback for each of the categories make sure you include okay so this thinks that it's a fiction book so it's mentioned plot and character development easy to update and then format it tells it exactly how to put the format together with recommendations and then it says don't include these code tags that i'm using to give you instructions\r\n\r\n\r\nat the end. And so this is good, but as we mentioned, like it thinks I'm writing a fiction book. That's not quite accurate. So we're going to hit continue and it's going to open up this whole screen here. And so now we've got the whole thing. And if I wanted to, I can run the prompt and get back and I can put a system prompt in or do any of that. But then I can also hit improve prompt.\r\n\r\n\r\nNikolas Hulewsky (20:47.897)\r\nYeah, so you gotta go edit it.\r\n\r\n\r\nNikolas Hulewsky (21:07.215)\r\nSo.\r\n\r\n\r\nMichael Greenberg (21:10.974)\r\nAnd I can say this is actually going to be used for, well actually let's not use this particular window. Let's take this and let's go back to the dashboard and then improve an existing prompt. And now we'll put this in and we'll say, okay, this is.\r\n\r\n\r\nactually going to be used for nonfiction.\r\n\r\n\r\nbusiness books targeting SMB executives Exclusively so we need to Make it punchier and More framework focused all those guys have ADHD anyway\r\n\r\n\r\nMichael Greenberg (22:16.716)\r\nAnd now we'll see for those of you listening, we see at the top it says add a prompt template and describe what you'd like to improve. This is going to take one to two minutes and use some Claude credits. And so then we hit improve prompt and now it's going through six steps. So first it's extracting examples. Now it's planning an initial draft and we can see it thinking, putting together a flow chart, going through reasoning, and now it's writing a draft.\r\n\r\n\r\nNikolas Hulewsky (22:42.565)\r\nWow.\r\n\r\n\r\nMichael Greenberg (22:47.19)\r\nIt's improving.\r\n\r\n\r\nNikolas Hulewsky (22:49.487)\r\nSo like this prompt, I look at it like this looks like a GPT that I would build in chat GPT.\r\n\r\n\r\nMichael Greenberg (22:57.272)\r\nSo like this is, and a GPT is just a prompt. It's just a system level prompt in most cases. And so now.\r\n\r\n\r\nNikolas Hulewsky (23:06.085)\r\nAnd so can you, you can build this within Claude and have your own, I don't know what other word to use for it, but like.\r\n\r\n\r\nMichael Greenberg (23:10.806)\r\nYou can use this. So we use the same prompt tool across. We use the Claude and thropic prompt generation tool for all of our stuff. so we, if we're writing a prompt for Gemini for chat GPT for anything, this is probably the tool we are using to write that prompt. Every one of my AI apprentices, gets introduced to this on day one.\r\n\r\n\r\nNikolas Hulewsky (23:31.909)\r\nInteresting.\r\n\r\n\r\nNikolas Hulewsky (23:36.133)\r\nAnd then you're not actually publishing it, you're just copying it and then putting it into whichever model you're using.\r\n\r\n\r\nMichael Greenberg (23:42.296)\r\nYeah. And so this now, like, if we're building an AI tool, like a GPT or something, we would use these tools to create better prompts and to force structure to our inputs and outputs. So that way we can build something that is going to be repeatably effective. And so I think this is a better prompt and it's a little puny. You can see it added emojis because I said punchy.\r\n\r\n\r\nNikolas Hulewsky (24:00.515)\r\nincredible.\r\n\r\n\r\nYeah.\r\n\r\n\r\nNikolas Hulewsky (24:10.469)\r\nDude, that is awesome. Okay, tell me again where I go find this.\r\n\r\n\r\nMichael Greenberg (24:13.762)\r\nSo if you go to council, console.anthropic.com, that's it. And so this is separate from the claw.com like subscription.\r\n\r\n\r\nNikolas Hulewsky (24:24.485)\r\nThat's it.\r\n\r\n\r\nNikolas Hulewsky (24:29.573)\r\nBut I've got to apply for an API key and then I won't be able to access this.\r\n\r\n\r\nMichael Greenberg (24:33.718)\r\nYeah, I'm not well, I'm not I think I think you get access as a result of applying. So like you create a developer account and then you have access to this thing.\r\n\r\n\r\nMichael Greenberg (24:49.26)\r\nYeah, see, and then you just. So that is like one of my favorite tools.\r\n\r\n\r\nNikolas Hulewsky (24:50.053)\r\nwas awesome.\r\n\r\n\r\nNikolas Hulewsky (24:55.395)\r\nI love it. Dude, is a that I love. I'm going to use that tool. I'm going use that tool today.\r\n\r\n\r\nMichael Greenberg (25:00.322)\r\nthat you never write a prompt again. You just tell it what you want. It does it for you.\r\n\r\n\r\nNikolas Hulewsky (25:04.001)\r\nNever write a prompt again. Dude, that's a tagline if I ever heard one. Freaking love it. Where's the best place for people to come find you, Michael?\r\n\r\n\r\nMichael Greenberg (25:08.461)\r\nYeah.\r\n\r\n\r\nMichael Greenberg (25:12.078)\r\nyou can find me at digital ops, playbook.com. That's that's my newsletter for all this sort of stuff. Can I show you a horror story as a one last thing? This is our anthropic usage for March.\r\n\r\n\r\nNikolas Hulewsky (25:16.741)\r\nOkay, digital.\r\n\r\n\r\nNikolas Hulewsky (25:22.703)\r\nSure, yeah, we got a few minutes, yeah.\r\n\r\n\r\nMichael Greenberg (25:31.086)\r\nThis is almost 800 million tokens in and 24 million tokens out. This costs like three, $4,000 in a month. No. So we released some new tools. They got used way too much. And now we've refactored. We're now down to almost zero usage. You can see when we turned on our new tools, it went.\r\n\r\n\r\nNikolas Hulewsky (25:43.077)\r\nIs that a normal cost for you?\r\n\r\n\r\nMichael Greenberg (25:59.854)\r\nto like near zero because we switched to Gemini. So the cost per run on the tool was at 50 cents. And now it's down to like half a cent. So that was a, I woke up to accounting like, yeah, you're spending, did you know you're spending $150 a day right now? No. So that's a.\r\n\r\n\r\nNikolas Hulewsky (26:00.877)\r\nmy gosh.\r\n\r\n\r\nHoly crap.\r\n\r\n\r\nNikolas Hulewsky (26:12.805)\r\nJeez, that's a massive drop. Holy crap. Yeah, be careful of your usage.\r\n\r\n\r\nNikolas Hulewsky (26:23.907)\r\nWhat is happening?\r\n\r\n\r\nMichael Greenberg (26:28.78)\r\nyou know, be wary if you deploy an AI tool.\r\n\r\n\r\nNikolas Hulewsky (26:29.177)\r\nHoly crap, that's so much money.\r\n\r\n\r\nMichael Greenberg (26:33.914)\r\nYeah, that's our biggest month in spend yet. Yeah. Thank you.\r\n\r\n\r\nNikolas Hulewsky (26:34.533)\r\nOkay, I love it. Bye, beware. Appreciate you, Michael.",
  "metadata": {
    "duration": "",
    "date": "2025-05-15",
    "platform_source": "Google Drive"
  }
}